{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA1\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Author: Pan Yang (panyangnlp@gmail.com)\n",
    "# Copyright 2017 @ Yu Zhen\n",
    "import gensim\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from time import time\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleanrn = re.compile('\\n')\n",
    "    cleantext = re.sub(cleanr, ' ', raw_html)\n",
    "    cleantext = re.sub(cleanrn,'',cleantext)\n",
    "    return cleantext\n",
    "\n",
    "\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    "\n",
    "    def __iter__(self):\n",
    "        for root, dirs, files in os.walk(self.dirname):\n",
    "            for filename in files:\n",
    "                file_path = (root + '/' + filename)\n",
    "                for line in open(file_path,encoding='utf-8'):\n",
    "                    sline = line.strip()\n",
    "                    if sline == \"\":\n",
    "                        continue\n",
    "                    rline = cleanhtml(sline)\n",
    "                    tokenized_line = ' '.join(word_tokenize(rline))\n",
    "                    is_alpha_word_line = [word for word in\n",
    "                                          tokenized_line.lower().split()\n",
    "                                          if word.isalpha()]\n",
    "                    yield is_alpha_word_line\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-f1f6a36ffefa>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-f1f6a36ffefa>\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    size=100,\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "data_path = 'C:/Users/Administrator/Desktop/test'\n",
    "begin = time()\n",
    "\n",
    "sentences = MySentences(data_path)\n",
    "dictionary = gensim.corpora.Dictionary(sentences)\n",
    "corpus = [dictionary.doc2bow(text) for text in sentences]\n",
    "model = gensim.models.Word2Vec(sentences,\n",
    "                               size=100,\n",
    "                               window=5,\n",
    "                               min_count=5,\n",
    "                               workers=multiprocessing.cpu_count())\n",
    "model.save(\"data/model/word2vec_gensim\")\n",
    "model.wv.save_word2vec_format(\"data/model/word2vec_org\",\n",
    "                              \"data/model/vocabulary\",\n",
    "                              binary=False)\n",
    "\n",
    "end = time()\n",
    "print\n",
    "\"Total procesing time: %d seconds\" % (end - begin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<ipython-input-2-1161036a9e3a>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-1161036a9e3a>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    tfidf_model = gensim.models.TfidfModel(corpus)\u001b[0m\n\u001b[1;37m                                                  ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "tfidf_model = gensim.models.TfidfModel(corpus)\n",
    "tfidf_m = tfidf_model[corpus]\n",
    "lda = gensim.models.LdaModel(tfidf_m, id2word=dictionary, num_topics=200)\n",
    "corpus_lda = lda[tfidf_m]\n",
    "lda_csc_matrix = gensim.matutils.corpus2csc(corpus_lda).transpose()\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "kmean = KMeans(n_clusters=10)\n",
    "kmean.fit(lda_csc_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " from sklearn.decomposition import PCA\n",
    "\n",
    "    weight = lda_csc_matrix.toArray()\n",
    "    pca = PCA(n_components=2)  # 输出两维\n",
    "    newData = pca.fit_transform(weight)  # 载入N维\n",
    "    print(newData)\n",
    "\n",
    "    # 5A景区\n",
    "    x1 = []\n",
    "    y1 = []\n",
    "    i = 0\n",
    "    while i < 400:\n",
    "        x1.append(newData[i][0])\n",
    "        y1.append(newData[i][1])\n",
    "        i += 1\n",
    "\n",
    "        # 动物\n",
    "    x2 = []\n",
    "    y2 = []\n",
    "    i = 400\n",
    "    while i < 600:\n",
    "        x2.append(newData[i][0])\n",
    "        y2.append(newData[i][1])\n",
    "        i += 1\n",
    "\n",
    "        # 人物\n",
    "    x3 = []\n",
    "    y3 = []\n",
    "    i = 600\n",
    "    while i < 800:\n",
    "        x3.append(newData[i][0])\n",
    "        y3.append(newData[i][1])\n",
    "        i += 1\n",
    "\n",
    "        # 国家\n",
    "    x4 = []\n",
    "    y4 = []\n",
    "    i = 800\n",
    "    while i < 1000:\n",
    "        x4.append(newData[i][0])\n",
    "        y4.append(newData[i][1])\n",
    "        i += 1\n",
    "\n",
    "        # 四种颜色 红 绿 蓝 黑\n",
    "    PCA.plt.plot(x1, y1, 'or')\n",
    "    PCA.plt.plot(x2, y2, 'og')\n",
    "    PCA.plt.plot(x3, y3, 'ob')\n",
    "    PCA.plt.plot(x4, y4, 'ok')\n",
    "    PCA.plt.show()\n",
    "\n",
    "    data_path = sys.argv[1]\n",
    "    begin = time()\n",
    "\n",
    "    sentences = MySentences(data_path)\n",
    "    dictionary = gensim.corpora.Dictionary(sentences)\n",
    "    corpus = [dictionary.doc2bow(text) for text in sentences]\n",
    "    model = gensim.models.Word2Vec(sentences,\n",
    "                                   size=100,\n",
    "                                   window=5,\n",
    "                                   min_count=5,\n",
    "                                   workers=multiprocessing.cpu_count())\n",
    "\n",
    "    model.save(\"data/model/word2vec_gensim\")\n",
    "    model.wv.save_word2vec_format(\"data/model/word2vec_org\",\n",
    "                                  \"data/model/vocabulary\",\n",
    "                                  binary=False)\n",
    "\n",
    "    end = time()\n",
    "    print\n",
    "    \"Total procesing time: %d seconds\" % (end - begin)\n",
    "\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
